1
00:00:04,690 --> 00:00:08,080
For this video, we're going to talk about prediction and inference,

2
00:00:08,080 --> 00:00:15,490
learning outcomes for you to be able to distinguish between prediction and inference and understand different meanings of the word inference.

3
00:00:15,490 --> 00:00:19,840
We've talked about prediction and inference a little bit before. I talked about inferential validity.

4
00:00:19,840 --> 00:00:24,280
This video, I'm going to talk more about what we mean by these concepts.

5
00:00:24,280 --> 00:00:31,840
So in prediction, we're trying to predict other values from the model with our penguins.

6
00:00:31,840 --> 00:00:35,710
We might be able to we might be looking at, OK. That can I predict.

7
00:00:35,710 --> 00:00:43,210
If I get a if I if you give me the flipper length of a penguin in the future, can I accurately predict its bodyweight for our movies?

8
00:00:43,210 --> 00:00:47,650
If you give me some critic ratings, I predict its audience response.

9
00:00:47,650 --> 00:00:54,930
Or can I predict its box office? Proceeds. Porten thing about prediction is that models don't need to be inferentially valid.

10
00:00:54,930 --> 00:01:02,850
And the quality and strength we estimate the quality and strength of the prediction by actually trying to use it to predict data.

11
00:01:02,850 --> 00:01:07,860
We haven't allowed it to seen to see. It's important to note the evaluation of the prediction.

12
00:01:07,860 --> 00:01:15,870
Accuracy does need to be statistically valid. Inference uses the models, structure and parameters to learn about the world.

13
00:01:15,870 --> 00:01:22,850
So we might want to learn about fundamental relationships, about penguin physiology.

14
00:01:22,850 --> 00:01:27,380
Its validity depends on assumptions that we introduced last week or in the last video,

15
00:01:27,380 --> 00:01:33,140
we talked about single very regressions and then we have various measures of its quality and strength.

16
00:01:33,140 --> 00:01:37,430
R squared is how much variance that explains P value is statistical significance.

17
00:01:37,430 --> 00:01:43,640
We're going to have checks for its various assumptions and we've got the coefficients which look at the strength of the relationship.

18
00:01:43,640 --> 00:01:48,300
So what we're trying to do inference we can make a statement of credit rating increases

19
00:01:48,300 --> 00:01:52,700
as the critic rating in crace of one point increases audience ready by point one.

20
00:01:52,700 --> 00:01:57,350
There'll be an inferential statement. It's making a claim about the relationship of these things.

21
00:01:57,350 --> 00:02:02,030
And we measure this with we've got our squared, as we saw in the last video of point three nine four.

22
00:02:02,030 --> 00:02:06,800
We've got a very small P value and we assume that it's a linear relationship.

23
00:02:06,800 --> 00:02:08,960
We assume that our observations are independent.

24
00:02:08,960 --> 00:02:16,840
That we've got these normal residuals and also that the residuals have equal variance or what we call Hommel Skip Mastec.

25
00:02:16,840 --> 00:02:23,890
I'm never not going to think that homo scare tactic and it's opposite hetero skin mastic are very strange words.

26
00:02:23,890 --> 00:02:28,760
So that's an inferential kind of claim. We're claiming a relationship and not necessarily causal.

27
00:02:28,760 --> 00:02:33,850
But we're claiming this correlational relationship prediction looks really similar.

28
00:02:33,850 --> 00:02:39,040
We can predict audience ratings using the model to point to eight plus one point one eight.

29
00:02:39,040 --> 00:02:44,900
Our top. And we measure this by saying, oh, what's mean absolute error?

30
00:02:44,900 --> 00:02:47,880
So if we take the the errors, those Epsilon's residuals,

31
00:02:47,880 --> 00:02:53,750
we take the absolute value and take the average is two point is point to eight six or the root mean squared errors

32
00:02:53,750 --> 00:03:00,980
point three five nine root means squared error is a very common measurement to the accuracy of a predictive model.

33
00:03:00,980 --> 00:03:06,560
And we're not making any assumptions.

34
00:03:06,560 --> 00:03:17,600
We don't even have to assume linearity. We can for this to be a useful predictor, it'll hopefully be a better predictor if we if it's actually linear.

35
00:03:17,600 --> 00:03:28,090
But if if all we care about is how accurate it is at predicting, then.

36
00:03:28,090 --> 00:03:32,560
We don't have to worry about all of our influence, inferential validity assumptions,

37
00:03:32,560 --> 00:03:36,400
but we also have to be very, very careful about the claims we make.

38
00:03:36,400 --> 00:03:45,550
We can claim it's useful for predicting, but we can't, from an invalid model, make claims about the underlying phenomenon that we care about.

39
00:03:45,550 --> 00:03:51,490
It does make the assumption that we have tested it on data that were not available for training.

40
00:03:51,490 --> 00:03:56,140
So what does that mean? So in a machine, what we call it, a machine learning setting.

41
00:03:56,140 --> 00:04:03,170
We often have what we call a trained test split. And so we take our input data.

42
00:04:03,170 --> 00:04:09,510
And we split it into two pieces. This is our input.

43
00:04:09,510 --> 00:04:17,070
We say 80 percent of the data. 80 percent of comment split goes into our training pool and 10 percent.

44
00:04:17,070 --> 00:04:24,460
Goes into our testing pool. We then fit our linear regression or whatever other model we're doing.

45
00:04:24,460 --> 00:04:31,360
We fit or train at. On the training data, it does not get to see the test data.

46
00:04:31,360 --> 00:04:35,320
So we're letting your model does not include the test data in the fitting process.

47
00:04:35,320 --> 00:04:40,930
And then we ask the model to predict the test outcomes using the test features.

48
00:04:40,930 --> 00:04:44,950
And what this does is it tests. It's easy to predict data data.

49
00:04:44,950 --> 00:04:48,730
I've seen. I just memorize all the data. I've seen it test, though.

50
00:04:48,730 --> 00:04:56,330
Can I learn a relationship from training data that generalizes to data that was not in the training data?

51
00:04:56,330 --> 00:05:02,650
And we called particularly we call the kind of learning that we're doing this week supervised learning because we have a thing,

52
00:05:02,650 --> 00:05:10,330
this continuous outcome variable that we're trying to predict. It's also important, though, to split before the exploratory analysis of features.

53
00:05:10,330 --> 00:05:16,840
I'm going to be talking more about train test splits in a later video dedicated to experimental setup.

54
00:05:16,840 --> 00:05:24,670
But this is the basic idea of how we how we set up data to be able to test predictive accuracy because we don't want to be able.

55
00:05:24,670 --> 00:05:31,210
We don't want to test the model's memory. We want to test its ability to predict things that's never seen before.

56
00:05:31,210 --> 00:05:34,360
We need to split, as I said before, exploratory analysis,

57
00:05:34,360 --> 00:05:39,700
because we don't want knowledge of the distribution of our data and our tests of our variables

58
00:05:39,700 --> 00:05:44,710
in our test data to affect our choice of variables in the model development process.

59
00:05:44,710 --> 00:05:46,960
And if we're going to be, say, trying different features,

60
00:05:46,960 --> 00:05:52,600
trying different variants of a model before we settle on the final one, we actually need to split into three partitions.

61
00:05:52,600 --> 00:05:58,030
We have our training data. We have tuning for optimizing the model, testing the predictive accuracy of different candidates,

62
00:05:58,030 --> 00:06:01,180
and then we have a test data that's saved for our final validation.

63
00:06:01,180 --> 00:06:09,180
Again, we're gonna be talking more in detail about why each of these splits is necessary in a later video.

64
00:06:09,180 --> 00:06:12,690
But I also said that I want you to understand different uses that determine for it.

65
00:06:12,690 --> 00:06:18,000
So here we're using the word inference to talk about the use of a data analysis of the

66
00:06:18,000 --> 00:06:23,670
use of a statistical model to understand or infer things about the underlying world.

67
00:06:23,670 --> 00:06:27,120
So we're trying to understand how movie preference works.

68
00:06:27,120 --> 00:06:35,110
We're trying to understand penguin physiology or we're trying to understand the hydrodynamics of.

69
00:06:35,110 --> 00:06:40,350
Of a river or of an a quarter of a marine processing plant.

70
00:06:40,350 --> 00:06:44,100
And we're trying to use the data we collected and the statistical models and

71
00:06:44,100 --> 00:06:51,780
analysis that we do of it to draw conclusions about the underlying real world.

72
00:06:51,780 --> 00:06:55,950
There's some other uses of inference, though, particularly one that comes up in data science,

73
00:06:55,950 --> 00:06:59,310
in machine learning is sometimes when we have a model we've trained.

74
00:06:59,310 --> 00:07:06,120
It's we've take her. We fit our linear regression. And we're using it to make predictions for additional for new data points.

75
00:07:06,120 --> 00:07:14,220
Like maybe you've you've trained up a statistical model that estimates the likelihood that a particular transaction is fraudulent.

76
00:07:14,220 --> 00:07:21,870
Now you're using that model as transactions are coming in to your online shopping portal and to determine how likely they are to be fraudulent.

77
00:07:21,870 --> 00:07:25,170
Sometimes that last stage is called in France,

78
00:07:25,170 --> 00:07:31,530
especially in the deep learning literature on some other machine learning literature is that that's the first stage of the model training stage.

79
00:07:31,530 --> 00:07:38,310
And the inference stage is if you actually go use the model to make inferences about new new data points that are coming in.

80
00:07:38,310 --> 00:07:47,160
So to sum up, inference uses a model structure and parameters to try to understand things about the world and draw generalizable knowledge.

81
00:07:47,160 --> 00:07:51,150
Prediction just uses a model to predict future observations,

82
00:07:51,150 --> 00:07:57,420
particularly though inference has stronger requirements for its validity than the usefulness of prediction.

83
00:07:57,420 --> 00:08:06,690
It is important to note, though, that just because you can yolo the statistics inside a predictor if all you care about is its predictive accuracy,

84
00:08:06,690 --> 00:08:15,870
you have to pay attention to the validity of the statistics you use to test if the predictor is actually a better predictor than something else.

85
00:08:15,870 --> 00:08:19,860
You can't cheat on those, but if your only goal is predictive accuracy,

86
00:08:19,860 --> 00:08:26,370
the linear model you're using for it doesn't need to need to meet all the requirements that it needs to meet.

87
00:08:26,370 --> 00:08:33,200
If you're trying to use it for inference.

